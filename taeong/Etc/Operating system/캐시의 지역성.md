# 캐시의 지역성

📌[참고하면 좋은 내용](https://www.notion.so/c01faff6e03641f9884a5a2da2d1acdf)

캐시가 무엇인지, 왜 캐시를 사용하는지를 알고 있어야 합니다. 관련한 좋은 글을 링크해둡니다. [https://parksb.github.io/article/29.html](https://parksb.github.io/article/29.html)

시간 지역성과 공간 지역성으로 나눌 수 있으며, **시간 지역성**은 `최근에 접근한 데이터에 다시 접근하는 경향`을 의미하고, **공간 지역성**은 최근 `접근한 데이터의 주변 공간에 다시 접근하는 경향`을 의미합니다.

<br>

---

<br>

# 캐시 메모리(Cache Memory)

- 속도가 빠른 장치와 느린 장치간의 속도차에 따른 병목 현상을 줄이기 위한 범용 메모리
- 캐시메모리는 주기억장치에서 자주 사용하는 프로그램과 데이터를 저장해두어 처리 속도를 빠르게 함

<br>

# 캐시의 지역성

### 캐시의 지역성(Cache Locality)이란?

캐시메모리의 역할을 제대로 수행하기 위해서는 CPU가 어떤 데이터를 원할 것인가를 어느 정도 예측할 수 있어야 한다. 캐시의 성능은 작은 용량의 캐시 메모리에 CPU가 이후에 참조할, 쓸모 있는 정보가 어느 정도 들어있느냐에 따라 좌우되기 때문이다.

이 때 **적중율(Hit rate)를 극대화** 시키기 위해 데이터 지역성(Locality)를 사용한다. 지역성의 전제조건으로 프로그램은 모든 코드나 데이터를 균등하게 Access 하지 않는다는 특성을 기본으로 한다. 즉, Locality란 기억 장치 내의 정보를 균일하게 Access 하는 것이 아닌 어느 한 순간에 특정 부분을 집중적으로 참조하는 특성인 것이다.

- **캐시 적중(Cache Hit)** : CPU가 액세스하려는 데이터가 이미 캐시에 적재되어있는 상태.
- **캐시 미스(Cache Miss)** : CPU가 액세스하려는 데이터가 캐시에 없어 주기억장치로부터 인출해 와야하는 상태.
- **캐시 적중률(Cache Hit rate)** : CPU가 원하는 데이터가 캐시에 있을 확률, `(캐시에 적중되는 횟수) / (전체 기억장치 액세스 횟수)`
- **미스율(Miss rate)** : CPU가 원하는 데이터가 캐시에 없을 확률, `1-(Cache Hit rate)`

<br>

# 지역성의 종류

데이터 지역성은 대표적으로 시간적 지역성(Tempora Locality)과 공간지역(Spatial Locality)로 나뉜다.

### 시간적 지역성(Temporal Locality)

시간적 지역성은 최근에 참조된 주소의 내용은 곧 다음에 다시 참조되는 특성이다.

메모리 상의 같은 주소에 여러 차례 읽기 쓰기를 수행할 경우, 상대적으로 작은 크기의 캐시를 사용해도 효율성을 꾀할 수 있다.

### 공간적 지역성(Spatial Locality)

공간적 지역성은 기억장치 내에 서로 인접하여 저장되어 있는 데이터들이 연속적으로 액세스 될 가능성이 높아지는 특성이다.

CPU 캐시나 디스크 캐시의 경우 한 메모리 주소에 접근할 때 그 주소뿐 아니라 해당 블록을 전부 캐시에 가져오게 된다.

이때 메모리 주소를 오름차순이나 내림차순으로 접근한다면, 캐시에 이미 저장된 같은 블록의 데이터를 접근하게 되므로 캐시의 효율성이 크게 향상된다.

<br>

# Caching line

- 캐시에 목적 데이터가 저장되어 있다면 바로 접근하여 출력할 수 있도록 캐시에 데이터를 저장할 때 **특정 자료구조를 사용하여 '묶음'으로 저장**하는 것
- 캐싱 라인을 기준으로 메모리에서 가져옴

[https://prinha.tistory.com/entry/System-Programming-프로세스의-스케줄링과-상태-변화](https://prinha.tistory.com/entry/System-Programming-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%9D%98-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81%EA%B3%BC-%EC%83%81%ED%83%9C-%EB%B3%80%ED%99%94)

<br>

---

<br>

## 💡면접 질문

### 1. **캐시 메모리는 어디에 위치해 있나요?**

- CPU 칩 안에 위치
- 각각 목적과 역할이 다른 여러 개의 캐시가 들어감

<br>

### 2. **L1, L2 캐시에 대해 설명해 주세요.**

<img src="https://user-images.githubusercontent.com/48792230/222904280-a640d115-b2ee-4dbc-9d6e-e1578e850a01.png" width="600"/>
<img src="https://user-images.githubusercontent.com/48792230/222904283-915eeb73-3bf1-47ee-948e-11aa244deb2a.png" width="600"/>

- `L1 Cache`: 프로세서와 가장 가까운 캐시. **속도**를 위해 I$와 D$로 나뉜다.
    - Instruction Cache (I$): 메모리의 TEXT 영역 데이터를 다루는 캐시.
    - Data Cache (D$): TEXT 영역을 제외한 모든 데이터를 다루는 캐시.
- `L2 Cache`: **용량**이 큰 캐시. 크기를 위해 L1 캐시처럼 나누지 않는다.
- `L3 Cache`: 멀티 코어 시스템에서 **여러 코어가 공유**하는 캐시.

<br>

### 3. 캐시에 올라오는 데이터는 어떻게 관리되나요?

- 캐시는 반응 속도가 빠른 SRAM(Static Random Access Memory)으로, 주소가 키(Key)로 주어지면 해당 공간에 즉시 접근할 수 있음 (메인메모리는 DRAM)
- = 캐시가 하드웨어로 구현한 해시 테이블(Hash table)과 같다는 의미
    - 해시 테이블의 시간 복잡도는 O(1)
- 캐시는 블록(Block)으로 구성됨. 각각의 블록은 데이터를 담고 있으며, 주소값을 키로써 접근할 수 있음

<br>

### 4. 캐시 메모리의 Mapping 방식에 대해 설명해 주세요.

- **사상(Mapping, 매핑) : 주기억장치로부터 캐시 메모리로 데이터를 전송하는 방법**으로 3가지 방법이 있다.
    - **직접 매핑(direct Mapping)**
        - 주기억장치의 블록들이 지정된 한 개의 캐시 라인으로만 사상될 수 있는 매핑 방법.
        - 간단하고 구현하는 비용이 적게드는 장점이 있지만 적중률이 낮아질 수 있다는 단점이 있다.
    - **어소시에이티브 매핑(Associative Mapping)**
        - 직접 매핑 방식의 단점을 보완한 방식.
        - 모든 태그들을 병렬로 검사하기 때문에 복잡하고 비용이 높다는 단점이 있어 거의 사용하지 않는다.
    - **세트-어소시에이티브 매핑(Set-Associative Mapping)**
        - 직접 매핑과 연관 매핑의 장점만을 취한 방식.
